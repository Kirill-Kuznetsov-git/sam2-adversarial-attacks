{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b28288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from PIL import Image, ImageDraw\n",
    "from segmentation_models_pytorch.losses import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a15e2f-c7e1-4e5d-862f-fcb751a60b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:2\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29bc90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask(image: Image, mask: np.ndarray, box, iter, alpha=0.7):\n",
    "    image = (np.array(image) / 255.).transpose(2, 0, 1)\n",
    "    mask = (np.array(mask) / 255.)\n",
    "    mask = np.stack([mask[0] * 87./255, mask[0] * 186./255, mask[0] * 168./255])\n",
    "\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    \n",
    "    image_transparency = (image * (1 - alpha) + mask * alpha).clip(0, 1)\n",
    "    \n",
    "    image = np.where(mask, image_transparency, image).clip(0, 1)\n",
    "    image = Image.fromarray((image.transpose(1, 2, 0) * 255).astype(dtype=np.uint8))\n",
    "    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "    x0, y0, x1, y1 = box\n",
    "    \n",
    "    for i in range(5):\n",
    "        draw.rectangle([x0 + i, y0 + i, x1 - i, y1 - i], outline=(0, 255, 0), width=1)\n",
    "\n",
    "    image.save('./bbox_frames/' + str(iter).zfill(4) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cc19e7-bdaf-4688-a512-eb093760c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square (coords):\n",
    "    return (coords[2] - coords[0]) * (coords[3] - coords[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2e4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('../images/GrabCut/data_GT/person6.jpg')\n",
    "image = np.array(image.convert(\"RGB\"))\n",
    "# image = image[:-1,:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d2e74a2-0c7c-4ffa-be2d-81760b8f2b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 450\n"
     ]
    }
   ],
   "source": [
    "h, w = image.shape[:2]\n",
    "print(h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b2dc0d-0cec-4f0b-9929-bf8086896e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mask = Image.open('../images/GrabCut/boundary_GT/person6.bmp')\n",
    "zero_mask = np.array(zero_mask)\n",
    "# zero_mask = zero_mask[:-1,:-1]\n",
    "zero_mask = torch.as_tensor(zero_mask, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e28150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user20/segment-anything-2/sam2/modeling/sam/transformer.py:23: UserWarning: Flash Attention is disabled as it requires a GPU with Ampere (8.0) CUDA capability.\n",
      "  OLD_GPU, USE_FLASH_ATTN, MATH_KERNEL_ON = get_sdpa_settings()\n"
     ]
    }
   ],
   "source": [
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "sam2_checkpoint = \"../../checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "# убираем отслеживание всех параметров\n",
    "for param in predictor.model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d95d48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6923b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_box = np.array([170, 206, 296, 282])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9fec49e-6dc2-4fe5-9b55-8da63b7784f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_input, unnorm_coords, labels, unnorm_box_input = predictor._prep_prompts(\n",
    "    point_coords=None, point_labels=None, box=input_box, mask_logits=None, normalize_coords=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0a0b08-d29b-4064-ad74-63ef4c9dbcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[386.8445, 351.5733],\n",
       "         [673.5645, 481.2800]]], device='cuda:2')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnorm_box_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e0ebda0-cb1d-44da-a8d1-622279f05ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes_n = torch.as_tensor(input_box, dtype=torch.float, device=predictor.device)\n",
    "# boxes = boxes_n.reshape(-1, 2, 2)\n",
    "# coords = boxes.clone()\n",
    "# coords[..., 0] = coords[..., 0] / w\n",
    "# print(coords)\n",
    "# coords[..., 1] = coords[..., 1] / h\n",
    "# print(coords)\n",
    "# coords = coords * 1024  # хз почему, мб макс разрешение sam2\n",
    "# print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "120d3fa0-0ecd-4aa8-a614-12341f8686fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем обратную нормализацию координат\n",
    "def back_norm(unnorm_box, w, h):\n",
    "    norm_box = unnorm_box/1024\n",
    "    coords = norm_box.clone()\n",
    "    coords[..., 0] = coords[..., 0] * w\n",
    "    coords[..., 1] = coords[..., 1] * h\n",
    "    box_coord = coords.squeeze(0).float().detach().cpu().numpy().flatten()\n",
    "    return box_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19d42360-603e-4c4f-958b-9bb6ad7b57c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiceLoss('binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b05940f-a5c2-4d92-9f8f-3677246c136b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iter =  0\n",
      "IoU tensor([[0.7196]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8217, grad_fn=<MeanBackward0>)\n",
      "reg 0.0\n",
      "\n",
      "\n",
      "iter =  100\n",
      "IoU tensor([[0.7217]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8254, grad_fn=<MeanBackward0>)\n",
      "reg 0.00038113742103576656\n",
      "\n",
      "\n",
      "iter =  200\n",
      "IoU tensor([[0.7251]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8299, grad_fn=<MeanBackward0>)\n",
      "reg 0.0011549952030181884\n",
      "\n",
      "\n",
      "iter =  300\n",
      "IoU tensor([[0.7241]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8343, grad_fn=<MeanBackward0>)\n",
      "reg 0.0024724491306304932\n",
      "\n",
      "\n",
      "iter =  400\n",
      "IoU tensor([[0.7209]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8378, grad_fn=<MeanBackward0>)\n",
      "reg 0.004994351991271973\n",
      "\n",
      "\n",
      "iter =  500\n",
      "IoU tensor([[0.7161]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8402, grad_fn=<MeanBackward0>)\n",
      "reg 0.012440087213516235\n",
      "\n",
      "\n",
      "iter =  600\n",
      "IoU tensor([[0.7115]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8424, grad_fn=<MeanBackward0>)\n",
      "reg 0.021828697264194487\n",
      "\n",
      "\n",
      "iter =  700\n",
      "IoU tensor([[0.7072]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8443, grad_fn=<MeanBackward0>)\n",
      "reg 0.03383830702056884\n",
      "\n",
      "\n",
      "iter =  800\n",
      "IoU tensor([[0.7029]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8461, grad_fn=<MeanBackward0>)\n",
      "reg 0.04851911535987854\n",
      "\n",
      "\n",
      "iter =  900\n",
      "IoU tensor([[0.6993]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8477, grad_fn=<MeanBackward0>)\n",
      "reg 0.06510724807128906\n",
      "\n",
      "\n",
      "iter =  1000\n",
      "IoU tensor([[0.6969]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8493, grad_fn=<MeanBackward0>)\n",
      "reg 0.08470919382333755\n",
      "\n",
      "\n",
      "iter =  1100\n",
      "IoU tensor([[0.6951]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8509, grad_fn=<MeanBackward0>)\n",
      "reg 0.10509793755807877\n",
      "\n",
      "\n",
      "iter =  1200\n",
      "IoU tensor([[0.6970]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8522, grad_fn=<MeanBackward0>)\n",
      "reg 0.14065543049964904\n",
      "\n",
      "\n",
      "iter =  1300\n",
      "IoU tensor([[0.6937]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8542, grad_fn=<MeanBackward0>)\n",
      "reg 0.16095407158136368\n",
      "\n",
      "\n",
      "iter =  1400\n",
      "IoU tensor([[0.6921]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8559, grad_fn=<MeanBackward0>)\n",
      "reg 0.188667930688858\n",
      "\n",
      "\n",
      "iter =  1500\n",
      "IoU tensor([[0.6322]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8638, grad_fn=<MeanBackward0>)\n",
      "reg 0.24200420610961912\n",
      "\n",
      "\n",
      "iter =  1600\n",
      "IoU tensor([[0.6954]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8586, grad_fn=<MeanBackward0>)\n",
      "reg 0.26818828092584607\n",
      "\n",
      "\n",
      "iter =  1700\n",
      "IoU tensor([[0.6947]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8584, grad_fn=<MeanBackward0>)\n",
      "reg 0.32284105776789185\n",
      "\n",
      "\n",
      "iter =  1800\n",
      "IoU tensor([[0.6794]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8605, grad_fn=<MeanBackward0>)\n",
      "reg 0.35651414000282283\n",
      "\n",
      "\n",
      "iter =  1900\n",
      "IoU tensor([[0.6501]], device='cuda:2', grad_fn=<WhereBackward0>)\n",
      "loss tensor(0.8637, grad_fn=<MeanBackward0>)\n",
      "reg 0.39999433595755096\n"
     ]
    }
   ],
   "source": [
    "iters = 2000\n",
    "lambda_reg = 0.0000001\n",
    "\n",
    "unnorm_box = unnorm_box_input\n",
    "unnorm_box.requires_grad = True\n",
    "opt = optim.Adam([unnorm_box], lr=1e-2)\n",
    "\n",
    "for iter in range(iters):\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    masks, iou_predictions, low_res_masks = predictor._predict(\n",
    "        unnorm_coords,\n",
    "        labels,\n",
    "        unnorm_box,\n",
    "        mask_input,\n",
    "        multimask_output=False,\n",
    "        return_logits=True\n",
    "    )\n",
    "    \n",
    "    masks_np = masks.clip(0, 1).squeeze(0).detach().cpu().numpy()*255\n",
    "    iou_predictions_np = iou_predictions.squeeze(0).float().detach().cpu().numpy()\n",
    "    low_res_masks_np = low_res_masks.squeeze(0).float().detach().cpu().numpy()\n",
    "    unnorm_coords_np = back_norm(unnorm_box, w, h)\n",
    "    \n",
    "    masks_np2 = masks_np.squeeze(0)\n",
    "    masks_loss = masks.cpu()\n",
    "    zero_mask_torch = zero_mask.unsqueeze(0).clip(0, 1)\n",
    "    \n",
    "    save_mask(image, masks_np, unnorm_coords_np, iter, alpha=0.7)\n",
    "    \n",
    "    loss = criterion(masks_loss, zero_mask_torch)\n",
    "    reg_loss = abs(square(input_box)-square(unnorm_coords_np))\n",
    "    \n",
    "    #минимизация\n",
    "    # total_loss = loss + lambda_reg * reg_loss**2\n",
    "    #максимизация\n",
    "    total_loss = -loss\n",
    "    \n",
    "    if iter % 100 == 0:\n",
    "        print('\\n\\niter = ', iter)\n",
    "        print('IoU', iou_predictions)\n",
    "        print('loss',loss)\n",
    "        print('reg',lambda_reg * reg_loss**2)\n",
    "    \n",
    "    total_loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a8f8eaf-cec9-4610-9859-b9ded5efa296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from '/home/user20/segment-anything-2/notebooks/sam2_adversarial_attacks/bbox_frames/%04d.jpg':\n",
      "  Duration: 00:01:20.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 450x600 [SAR 1:1 DAR 3:4], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mprofile High, level 3.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=19 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'bbox_video/out55.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 450x600 [SAR 1:1 DAR 3:4], q=2-31, 30 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame= 2400 fps=604 q=-1.0 Lsize=     927kB time=00:01:19.90 bitrate=  95.0kbits/s dup=400 drop=0 speed=20.1x    \n",
      "video:898kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.222922%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mframe I:10    Avg QP:17.83  size: 70137\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mframe P:605   Avg QP:22.57  size:   263\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mframe B:1785  Avg QP:32.38  size:    33\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mconsecutive B-frames:  0.8%  0.1%  0.5% 98.7%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mmb I  I16..4:  0.0% 96.0%  4.0%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mmb P  I16..4:  0.0%  0.1%  0.0%  P16..4:  0.8%  0.1%  0.1%  0.0%  0.0%    skip:98.9%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  0.4%  0.0%  0.0%  direct: 0.0%  skip:99.6%  L0:40.3% L1:59.6% BI: 0.2%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0m8x8 transform intra:93.0% inter:65.3%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mcoded y,uvDC,uvAC intra: 97.1% 94.3% 74.6% inter: 0.1% 0.1% 0.0%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mi16 v,h,dc,p: 87% 11%  0%  2%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 19% 17%  7%  7%  7% 10%  9% 11%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 15% 50% 10%  4%  4%  3%  4%  4%  6%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mi8c dc,h,v,p: 43% 27% 22%  8%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mref P L0: 74.9%  4.3% 10.2% 10.6%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mref B L0: 81.3% 14.8%  3.8%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mref B L1: 85.9% 14.1%\n",
      "\u001b[1;36m[libx264 @ 0x55d11237e980] \u001b[0mkb/s:91.86\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i /home/user20/segment-anything-2/notebooks/sam2_adversarial_attacks/bbox_frames/%04d.jpg -r 30 bbox_video/out55.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e7056-fd37-4dee-8c28-2c4f51d826c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liza_env",
   "language": "python",
   "name": "liza_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
